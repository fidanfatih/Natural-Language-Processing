{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## NLP Lab-1"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word_embedding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Word2Vec"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install gensim"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ertuğrul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.0.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\ertuğrul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\ertuğrul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ertuğrul\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (5.1.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#pip install --upgrade pip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "from gensim.models import Word2Vec"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Ertuğrul\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "text = open(\"hurriyet.txt\", \"r\", encoding=\"utf8\")\r\n",
    "text = text.read()\r\n",
    "list_sent = text.split(\"\\n\")\r\n",
    "\r\n",
    "corpus = []\r\n",
    "\r\n",
    "for sent in list_sent:\r\n",
    "    corpus.append(sent.split())\r\n",
    "# Corpus taki cümleleri split ile ayırarak liste halinde corpus listesine ekliyoruz."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(corpus[:5])\r\n",
    "# İlk beş cümleye bakıyoruz."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['iran', 'devlet', 'televizyonu', 'ülkedeki', 'eyaletin', 'sinde', 'yapılan', 'reformcuları', 'protesto', 'amaçlı', 'yürüyüşlere', 'milyonlarca', 'kişinin', 'katıldığını', 'bildirdi'], ['gösterilerde', 'fitnecilere', 'ölüm', 'münafıklara', 'ölüm', 'abd', 'ye', 'ölüm', 'ingiltere', 'ye', 'ölüm', 'sloganları', 'atıldı'], ['dini', 'lider', 'ali', 'hamaney', 've', 'cumhurbaşkanı', 'mahmud', 'ahmedinejad', 'ı', 'destekleyen', 'iranlılar', 'son', 'olaylarda', 'yeğeni', 'öldürülen', 'mir', 'hüseyin', 'musevi', 'başta', 'olmak', 'üzere', 'muhalefet', 'liderlerini', 'kınadılar'], ['musevi', 'ye', 'ölüm', 've', 'idam', 'idam', 'sloganları', 'duyuldu'], ['muhalefet', 'liderleri', 'kaçtı', 'mı', 'aşure', 'günü', 'yaşanan', 'çatışmalarda', 'devlet', 'kaynaklarına', 'göre', 'u', 'terörist', 'olmak', 'üzere', 'kişi', 'ölmüştü']]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = Word2Vec(corpus, vector_size = 100, window =5, min_count=5, sg=1)\r\n",
    "# windows = 5; kelimeyi o kelimenin sağında ve solundaki beş kelime kalıbı ile öğren demek. Örnek: 'iran', 'devlet', 'televizyonu', 'ülkedeki', 'eyaletin','sinde' burada İran kelimesini ele alırsak sağındaki beş kelime ile kullanımını değerlendiriyor, bu değerlendirmeyi bütün corpus taki (Iran birçok cümlede geçiyor) kullanımlarına bakarak bu kelimere olasılık değeri atıyor. \r\n",
    "# vector_size = 100 ile 100 lük vectorler oluşturuyoruz.\r\n",
    "# min_count=5;  kelime corpus ta 5 den az kullanılmıs ise onu öğrenme demek.\r\n",
    "# sg=1; hedef kelimeyi çıkararak sağında ve solundaki birer kelime ile bulmaya çalışıyor. (ben .... geldim (hedef ... = eve)). Bu modele kelimenin farklı anlamlarını öğrenmesini sağlır\r\n",
    "# Word2Vec kelime kalıplarını (isim tamlaması, sıfat tamlaması, deyim vb.) öğrenirken yukarıdaki parametreleri kullanarak kelime ile aynı anlamda olan veya o kelimeden sonra veya önce gelen kelimelerin kullanılma olasılıklarına göre öğreniyor ve tahminlemeyi ona göre yapıyor.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model.wv.most_similar(\"birşey\")\r\n",
    "# benzer veya birlikte kullanılan kelimeleri kontrol ediyoruz."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('muydu', 0.8356281518936157),\n",
       " ('sorunum', 0.8338453769683838),\n",
       " ('şeyim', 0.8317961096763611),\n",
       " ('derler', 0.8279939889907837),\n",
       " ('yapmadım', 0.8230245113372803),\n",
       " ('utanılacak', 0.8158398270606995),\n",
       " ('olmadığımı', 0.8150843977928162),\n",
       " ('stratejimiz', 0.8146624565124512),\n",
       " ('nedenimiz', 0.812784731388092),\n",
       " ('şüpheniz', 0.8124085664749146)]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.wv.most_similar(\"mavi\")\r\n",
    "# benzer veya birlikte kullanılan kelimeleri kontrol ediyoruz."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('marmara', 0.9009339213371277),\n",
       " ('gemisine', 0.6696080565452576),\n",
       " ('baskınıyla', 0.6331865191459656),\n",
       " ('baskınına', 0.6215893030166626),\n",
       " ('baskınının', 0.613463282585144),\n",
       " ('filo', 0.6006196141242981),\n",
       " ('dökme', 0.5973791480064392),\n",
       " ('filosundaki', 0.5791763067245483),\n",
       " ('baskından', 0.5778861045837402),\n",
       " ('baskınından', 0.5718426704406738)]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.wv.most_similar(\"eve\")\r\n",
    "# benzer veya birlikte kullanılan kelimeleri kontrol ediyoruz."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('evine', 0.8124664425849915),\n",
       " ('dükkana', 0.757697582244873),\n",
       " ('mağazaya', 0.7561960816383362),\n",
       " ('arabaya', 0.741432249546051),\n",
       " ('apartmana', 0.7386541366577148),\n",
       " ('hapishaneye', 0.7265657782554626),\n",
       " ('arabasına', 0.7204165458679199),\n",
       " ('odasına', 0.7178511619567871),\n",
       " ('otobüse', 0.7152799963951111),\n",
       " ('ofise', 0.7077111005783081)]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model.wv.most_similar(positive=['öğrenme', 'doktor'], negative=['tedavi'], topn=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('psikoloji', 0.653346061706543)]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "model.wv.most_similar(positive=['ankara', 'almanya'], negative=['berlin'], topn=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('rusya', 0.5980214476585388)]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Glove"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\r\n",
    "from gensim.models import KeyedVectors\r\n",
    "# glove2word2vec un Word2Vec ten farkı vektör olasılıklarını sürekli güncelliyor."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "glove_model = \"glove.6B.100d.txt\"\r\n",
    "word2vec = \"glove.6B.100d.word2vec\"\r\n",
    "glove2word2vec(glove_model, word2vec)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-13-61b6e809fd94>:3: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_model, word2vec)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 100 to array axis with dimension 1",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-61b6e809fd94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mglove_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"glove.6B.100d.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mword2vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"glove.6B.100d.word2vec\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mglove2word2vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1517\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 )\n\u001b[1;32m-> 1519\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\scripts\\glove2word2vec.py\u001b[0m in \u001b[0;36mglove2word2vec\u001b[1;34m(glove_input_file, word2vec_output_file)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \"\"\"\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mglovekv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglove_input_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mnum_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglovekv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglovekv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m         \"\"\"\n\u001b[1;32m-> 1630\u001b[1;33m         return _load_word2vec_format(\n\u001b[0m\u001b[0;32m   1631\u001b[0m             \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   1911\u001b[0m             )\n\u001b[0;32m   1912\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1913\u001b[1;33m             \u001b[0m_word2vec_read_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1914\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1915\u001b[0m         logger.info(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_text\u001b[1;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, encoding)\u001b[0m\n\u001b[0;32m   1817\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"unexpected end of input; is count incorrect or file otherwise damaged?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m         \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_word2vec_line_to_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1819\u001b[1;33m         \u001b[0m_add_word_to_kv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_add_word_to_kv\u001b[1;34m(kv, counts, word, weights, vocab_size)\u001b[0m\n\u001b[0;32m   1756\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"duplicate word '%s' in word2vec file, ignoring all but first\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1758\u001b[1;33m     \u001b[0mword_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1759\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36madd_vector\u001b[1;34m(self, key, vector)\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot copy sequence with size 100 to array axis with dimension 1"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2 = KeyedVectors.load_word2vec_format(word2vec)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.most_similar(\"blue\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('red', 0.8435065150260925),\n",
       " ('black', 0.8065882921218872),\n",
       " ('pink', 0.786806046962738),\n",
       " ('green', 0.7868044376373291),\n",
       " ('purple', 0.7847141623497009),\n",
       " ('yellow', 0.7777267694473267),\n",
       " ('gray', 0.7732225060462952),\n",
       " ('bright', 0.743113100528717),\n",
       " ('white', 0.7365070581436157),\n",
       " ('dark', 0.717019259929657)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.most_similar(\"doctor\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('physician', 0.7673240303993225),\n",
       " ('nurse', 0.75215083360672),\n",
       " ('dr.', 0.7175194025039673),\n",
       " ('doctors', 0.7080884575843811),\n",
       " ('patient', 0.7074184417724609),\n",
       " ('medical', 0.6995992660522461),\n",
       " ('surgeon', 0.6905338168144226),\n",
       " ('hospital', 0.6900930404663086),\n",
       " ('psychiatrist', 0.658909797668457),\n",
       " ('dentist', 0.6447421312332153)]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.most_similar(positive=[\"woman\", \"father\"], negative=[\"man\"], topn=1)\r\n",
    "# \"father\" \"man\" ise \"woman\" \"mother\" olur."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('mother', 0.9024619460105896)]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.most_similar(positive=[\"woman\", \"brother\"], negative=[\"man\"], topn=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('daughter', 0.8917792439460754)]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.most_similar(positive=[\"ankara\", \"germany\"], negative=[\"berlin\"], topn=1)\r\n",
    "# germany den berlin i çıkrırsak, ankara yurkey verir."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('turkey', 0.81471186876297)]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.most_similar(positive=[\"teach\", \"doctor\"], negative=[\"treat\"], topn=1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('teacher', 0.7610154151916504)]"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Not. Word Embedding lerin amacı modele kelime kalıpları öğretmek. "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit (system)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "interpreter": {
   "hash": "43a9cd95aa030499ef934e4da31e07dde54f3fc3a1fd0cc4aeef7f16459ee2ac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}